---
output: html_document
editor_options: 
  chunk_output_type: console
---
<<<<<<< HEAD
---
title: "Data Management Group Assignment"
output: html_document
date: "2024-03-07"
editor_options: 
chunk_output_type: console
---
=======

>>>>>>> 61b49273c2c69a33c1fc130db359f453a1872bcf

# Introduction
The e-commerce sector relies heavily on data-driven insights to understand client behavior, enhance operations, and drive growth. This study describes our comprehensive strategy to emulate a real-world e-commerce data environment, which includes database design, data generation, management, automation, and data analysis. Our goal is to gain a comprehensive understanding of the entire data management process and exhibit skill in using programs such as SQLite, python, GitHub Actions, R, and Quarto.


# Database Design and Implementation
The first step in building our e-commerce database was to design the E-R diagram. Creating the ER diagram was an iterative process. 

Our first version(Figure 1) was too complex involving more than ten entities and relationship involving multiple loops. We also included participation constraints which we then removed for simplicity. After modifying the E-R diagram multiple times throughout the process to account for mistakes that hindered implementation as well as difficulties in data generation we reached our final diagram (Figure 2).

## E-R Diagram Design
### E-R Diagram

Figure 1: Our first E-R diagram
```{r}
knitr::opts_chunk$set(echo = TRUE,comment=NA,attr.source='.numberLines')
rm(list=ls())

library(png)
library(grid)

ER_1 <- readPNG("E-R Diagram First Version.png")

grid.raster(ER_1)
```

Figure 2: Our final E-R diagram
Contains 6 main entities and their attributes. Several 1 to N relationships, one m to n relationship between Product and Customer and 2 self referencing relationships. 
```{r}
ER <- readPNG("E-R Diagram.png")

grid.raster(ER)
```


### Assumption Made for Cardinality
We made several assumptions about cardinality of the relationships shown below together with the relationship sets:

1.  Users have unique email addresses – used for login.
2.  Suppliers have unique email addresses – used for login
3.  Passwords can be the same for different users (customers or suppliers).
4.  Each customer can be referred by only one customer at most.
5.  Each customer can refer more than one customer.
6.  Suppliers can sell multiple products, but one product can only be sold by one supplier.
7.  Each order is made by one customer.
8.  Each shipment (shipment ID) will only contain one order
9.  Each product can only use one voucher; each order can apply multiple vouchers.
10. Each product can belong to only one sub-category.
11. Each sub-category must be categorized in one parent-category.
12. One warehouse can contain multiple products; one product can only be stored in one warehouse.
13. Each customer can order multiple products and each product can be bought by multiple customers.
14. All products within one order will be shipped together in one shipment.

### Relationship Sets

Figure 3: Relationship Sets
```{r}
Cardinality <- readPNG("Cardinality.png")

grid.raster(Cardinality)
```


## SQL Database Schema Creation
Following the conceptual modelling we converted the E-R diagram to the logical schema converting each entity and each many to many relationship to a separate table including the primary and foreign keys. 

### Logical Schema
```{r}
LogicalSchema <- readPNG("logical schema.png")

grid.raster(LogicalSchema)
```

### Database Creation
```{r}
#install.packages("readr")
#install.packages("RSQLite")
install.packages("dplyr")
install.packages("chron")
install.packages("ggplot2")
library(readr)
library(RSQLite)
library(dplyr)
library(chron)
library(ggplot2)
```
This establishes a connection to the SQLite database named "e-commerce.db" and assigns it to the variable my_connection. The SQL code inside the R markdown chunk defines the schema for the Category table. 

```{r connect}
my_connection <- RSQLite::dbConnect(RSQLite::SQLite(),"e-commerce.db")
                            
```


**Create Category table**

It first checks if the table exists and drops it if it does, ensuring a clean slate for creating the table. 

```{sql connection=my_connection}
DROP TABLE IF EXISTS Category;
```

```{sql connection=my_connection}
CREATE TABLE IF NOT EXISTS Category(
  category_id VARCHAR(20) PRIMARY KEY NOT NULL,
  category_name VARCHAR (20) NOT NULL,
  parent_id VARCHAR(20),
  parent_name VARCHAR (20)
  );
  
```

Create Customer table

```{sql connection=my_connection}
DROP TABLE IF EXISTS Customer;
```

```{sql connection=my_connection}
CREATE TABLE IF NOT EXISTS Customer(
  customer_id VARCHAR(50) PRIMARY KEY NOT NULL,
  email VARCHAR (100) NOT NULL,
  first_name VARCHAR (100) NOT NULL,
  last_name VARCHAR (100) NOT NULL,
  street_name VARCHAR (100) NOT NULL,
  post_code VARCHAR(64) NOT NULL,
  city VARCHAR (100) NOT NULL,
  password_c VARCHAR (10) NOT NULL, 
  phone_number INT (11) NOT NULL,
  referral_by VARCHAR(50)
  );
```

Create Supplier table

```{sql connection=my_connection}
DROP TABLE IF EXISTS Supplier;
```

```{sql connection=my_connection}
CREATE TABLE IF NOT EXISTS Supplier (
    seller_id VARCHAR(50) PRIMARY KEY NOT NULL,
    seller_store_name VARCHAR(100),
    supplier_email VARCHAR(255),
    password_s VARCHAR(255),
    receiving_bank VARCHAR(50),
    seller_rating INT,
    seller_phone_number VARCHAR(20),
    seller_address_street VARCHAR(255),
    s_post_code VARCHAR(50),
    s_city VARCHAR(50)
    );

```

Create Warehouse table

```{sql connection=my_connection}
DROP TABLE IF EXISTS Warehouse;
```

```{sql connection=my_connection}
CREATE TABLE IF NOT EXISTS Warehouse (
    warehouse_id VARCHAR(50) PRIMARY KEY NOT NULL,
    capacity INT,
    current_stock INT,
    w_city VARCHAR(50),
    w_post_code VARCHAR(50),
    w_address_street VARCHAR(255)
    );
```

Create Product table

```{sql connection=my_connection}
DROP TABLE IF EXISTS Product;

```

```{sql connection=my_connection}
CREATE TABLE IF NOT EXISTS Product (
  product_id INT PRIMARY KEY NOT NULL,
  product_name VARCHAR(50),
  category_id VARCHAR(20),
  warehouse_id VARCHAR(50),
  seller_id VARCHAR(50),
  product_weight FLOAT,
  product_price FLOAT,
  product_size VARCHAR(20),
  FOREIGN KEY (seller_id) REFERENCES Supplier(seller_id)
  FOREIGN KEY (category_id) REFERENCES Category(category_id),
  FOREIGN KEY (warehouse_id) REFERENCES Warehouse(warehouse_id)
  );
```

Create Shipment table

```{sql connection=my_connection}
DROP TABLE IF EXISTS Shipment;

```

```{sql connection=my_connection}
CREATE TABLE IF NOT EXISTS Shipment (
    shipment_id VARCHAR(50) PRIMARY KEY NOT NULL,
    shipping_method VARCHAR(50),
    shipping_charge FLOAT
    );
```

Create Orders table

```{sql connection=my_connection}
DROP TABLE IF EXISTS Orders;
```

```{sql connection=my_connection}
CREATE TABLE IF NOT EXISTS Orders (
    order_id VARCHAR(50) NOT NULL,
    order_date DATE NOT NULL,
    order_status VARCHAR(50),
    quantity_of_product_ordered INT,
    payment_method VARCHAR(50),
    voucher_value INT,
    review_rating INT,
    shipment_id VARCHAR(50),
    product_id VARCHAR(50) NOT NULL,
    customer_id VARCHAR(50) NOT NULL,
    PRIMARY KEY (order_id, customer_id, product_id),

    FOREIGN KEY (shipment_id) REFERENCES Shipment(shipment_id),
    FOREIGN KEY (customer_id) REFERENCES Customer(customer_id),
    FOREIGN KEY (product_id) REFERENCES Product(product_id)
    );
    
```


# Data Generation and Management
## Synthetic Data Generation
We started with Mockaroo but Python gives more flexibility and customization possibilities for data generation. The team employed python 'faker' package, combined with tools such as ChatGPT, to generate synthetic data. For example, we can ask ChatGPT give us a list for postcode and city names:
```{}
postcode_city_data = {
    "AB10": "Aberdeen",
    "AB22": "Aberdeen",
    "EH1": "Edinburgh",
    "EH8": "Edinburgh",
    "G1": "Glasgow",
    "G2": "Glasgow",
    "KA1": "Kilmarnock",
    "KA22": "Ardrossan",
    "IV1": "Inverness",
    "IV2": "Inverness",
    "KY1": "Kirkcaldy",
    "KY7": "Glenrothes",
    "DG1": "Dumfries",
    "DG6": "Castle Douglas",
    "PA1": "Paisley",
    "PA19": "Gourock",
    "DD1": "Dundee",
    "DD10": "Montrose",
    "ML1": "Motherwell",
    "ML12": "Biggar"
}
```

Then, we used 'faker' package in python to generate customer data as follows:
```{}
def customer_data(num_customers, postcode_city_data, filename):
    fake = Faker()
    customer_id_set = set()
    with open(filename, 'w', newline='') as file:
        writer = csv.writer(file, quoting=csv.QUOTE_NONNUMERIC)
        writer.writerow(['customer_id', 'email', 'first_name', 'last_name', 'street_name', 'post_code', 'city', 'password_c', 'phone_number', 'referral_by'])
        
        # Generate list of customer IDs
        while len(customer_id_set) < num_customers:
            customer_id_set.add(fake.random_int(min=10001, max=50000))
        
        customer_ids = list(customer_id_set)  # Convert set to list for easy popping
        random.shuffle(customer_ids)  # Shuffle the list of customer IDs
        
        for _ in range(num_customers):
            post_code, city = random.choice(list(postcode_city_data.items()))
            street_name = fake.street_address()
            customer_id = customer_ids.pop()  # Get a customer ID and remove it from the list
            first_name = fake.first_name()
            last_name = fake.last_name()
            # Create email using first name and last name
            email = f"{first_name.lower()}.{last_name.lower()}@gmail.com"
            password_c = fake.password()
            phone_number = '7' + str(fake.random_number(digits=9)) 
            if customer_ids:
                referral_by = random.choice(customer_ids)
            else:
                referral_by = None

            writer.writerow([
                customer_id,
                email,
                first_name,
                last_name,
                street_name,
                post_code,
                city,
                password_c,
                phone_number,
                referral_by
            ])
    return list(customer_id_set)

```

## Assumptions Made for Data Generation Background
1. This is a fashion company that sells mostly clothes and accessories.
2. Seller rating is an integer between 1 and 5.
3. Product rating is an integer between 1 and 5.
4. All IDs are unique series of numerical digits (only integer values).
5. The available sizes for all products are between XS to XL.
6. The price supplied by the supplier is the price the product is sold at (before a voucher is applied). 
7. All prices shown are in pounds.
8. Product weight is in grams.
9. A customer can leave different reviews for different products in the same order.
10. A customer can purchase at most 8 different products in one order.
11. Product rating can only be given and shown after the order is done.
12. If the customer apply for return, then all products in that order will be returned together, and the review rating for the product will not be shown. 
13. There are 5 order statuses: processing, paid, shipping, done, and return. 
14. Orders cannot be cancelled but can be returned.  
15. There are 3 shipping methods: one-day, three-days, and seven-day.
16. Shipping charge is based on which shipping methods the customer chose. 17. There are 5 types of payment methods: Apple Pay, Mastercard, Visa, Google Pay, Paypal. A customer can only pay via one payment method for each order.
18. The vouchers are price discounts in pounds.
19. Each product can only use one voucher; each order can apply to multiple vouchers. 
20. voucher_value equals zero means that no discount is applied to that ordered product.

## Data Import

Read .csv files from the old_data folder, and make sure that some columns such as ids are character instead of number, so that when writing them to the database, they will not show in decimal format.

```{r dataloading,message=FALSE,warning=FALSE}
Category <- readr::read_csv("/cloud/project/old_data/category_data.csv")
Category$category_id <- as.character(Category$category_id)
Category$parent_id <- as.character(Category$parent_id)


Customer <- readr::read_csv("/cloud/project/old_data/customer_data.csv")
Customer$customer_id <- as.character(Customer$customer_id)
Customer$referral_by <- as.character(Customer$referral_by)


Supplier <- readr::read_csv("/cloud/project/old_data/supplier_data.csv")
Supplier$seller_id <- as.character(Supplier$seller_id)


Warehouse <- readr::read_csv("/cloud/project/old_data/warehouse_data.csv")
Warehouse$warehouse_id <- as.character(Warehouse$warehouse_id)


Product <- readr::read_csv("/cloud/project/old_data/product_data.csv")
Product$product_id <- as.character(Product$product_id)
Product$seller_id <- as.character(Product$seller_id)
Product$warehouse_id <- as.character(Product$warehouse_id)
Product$category_id <- as.character(Product$category_id)


Shipment <- readr::read_csv("/cloud/project/old_data/shipment_data.csv")
Shipment$shipment_id <- as.character(Shipment$shipment_id)


Orders <- readr::read_csv("/cloud/project/old_data/order_data.csv")

Orders$order_date <- as.Date(Orders$order_date, format = "%Y/%m/%d")
Orders$order_date <- as.character(Orders$order_date)
Orders$order_id <- as.character(Orders$order_id)
Orders$customer_id <- as.character(Orders$customer_id)
Orders$product_id <- as.character(Orders$product_id)
Orders$shipment_id <- as.character(Orders$shipment_id)

```

Before writing data into the database, we would check the uniqueness of primary key for all of the file.
```{r checkprimary,message=FALSE,warning=FALSE,attr.source='.numberLines'}
all_files <- list.files("old_data/")


for (variable in all_files) {
  this_filepath <- paste0("old_data/",variable)
  this_file_contents <- readr::read_csv(this_filepath)
  number_of_rows <- nrow(this_file_contents)
  
  print(paste0("Checking for: ",variable))
  
  print(paste0(" is ",nrow(unique(this_file_contents[,1]))==number_of_rows))
}
```
Except for order data, the uniqueness of the primary keys in other data are ensured. Since the primary key for Orders table is a composite of three columns, as explained above, we will check the primary key for this table after appending data into the database.



Write these data to the e-commerce database using **append=TRUE** so that
the data will not overwrite the data type we set when creating empty tables.

```{r writebacktodb}
RSQLite::dbWriteTable(my_connection,"Category",Category,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Customer",Customer,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Supplier",Supplier,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Warehouse",Warehouse,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Product",Product,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Shipment",Shipment,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Orders",Orders,append=TRUE)

```

Use **PRAGMA table_info()** to verify the primary key, column names, data type, and NOT NULL setting of each table we created.

```{sql connection=my_connection}
PRAGMA table_info(Customer);
```

```{sql connection=my_connection}
PRAGMA table_info(Category);
```

```{sql connection=my_connection}
PRAGMA table_info(Supplier);
```

```{sql connection=my_connection}
PRAGMA table_info(Warehouse);
```

```{sql connection=my_connection}
PRAGMA table_info(Product);
```

```{sql connection=my_connection}
PRAGMA table_info(Shipment);
```

```{sql connection=my_connection}
PRAGMA table_info(Orders);
```
Since the primary of Orders table are a composite of order_id, customer_id, and product_id, so in the 'pk' column it marks these three columns from 1 to 3 and leaves others as 0.


We then read data in the new_data folder in to simulate what would happen when new data comes in to the current database.

```{r newdataloading,message=FALSE,warning=FALSE}
Category_new <- readr::read_csv("/cloud/project/new_data/category_data_new.csv")
Category_new$category_id <- as.character(Category_new$category_id)
Category_new$parent_id <- as.character(Category_new$parent_id)


Customer_new <- readr::read_csv("/cloud/project/new_data/customer_data_new.csv")
Customer_new$customer_id <- as.character(Customer_new$customer_id)
Customer_new$referral_by <- as.character(Customer_new$referral_by)


Supplier_new <- readr::read_csv("/cloud/project/new_data/supplier_data_new.csv")
Supplier_new$seller_id <- as.character(Supplier_new$seller_id)


Warehouse_new <- readr::read_csv("/cloud/project/new_data/warehouse_data_new.csv")
Warehouse_new$warehouse_id <- as.character(Warehouse_new$warehouse_id)


Product_new <- readr::read_csv("/cloud/project/new_data/product_data_new.csv")
Product_new$product_id <- as.character(Product_new$product_id)
Product_new$seller_id <- as.character(Product_new$seller_id)
Product_new$warehouse_id <- as.character(Product_new$warehouse_id)
Product_new$category_id <- as.character(Product_new$category_id)


Shipment_new <- readr::read_csv("/cloud/project/new_data/shipment_data_new.csv")
Shipment_new$shipment_id <- as.character(Shipment_new$shipment_id)


Orders_new <- readr::read_csv("/cloud/project/new_data/order_data_new.csv")

Orders_new$order_date <- as.Date(Orders_new$order_date, format = "%Y/%m/%d")
Orders_new$order_date <- as.character(Orders_new$order_date)
Orders_new$order_id <- as.character(Orders_new$order_id)
Orders_new$customer_id <- as.character(Orders_new$customer_id)
Orders_new$product_id <- as.character(Orders_new$product_id)
Orders_new$shipment_id <- as.character(Orders_new$shipment_id)

```


Before writing data into the database, we would check the uniqueness of primary key for all of the file.
```{r checkprimary2,message=FALSE,warning=FALSE,attr.source='.numberLines'}
all_files <- list.files("new_data/")


for (variable in all_files) {
  this_filepath <- paste0("new_data/",variable)
  this_file_contents <- readr::read_csv(this_filepath)
  number_of_rows <- nrow(this_file_contents)
  
  print(paste0("Checking for: ",variable))
  
  print(paste0(" is ",nrow(unique(this_file_contents[,1]))==number_of_rows))
}
```
Except for order data, the uniqueness of the primary keys in other data are ensured. Since the primary key for Orders table is a composite of three columns, as explained above, we will check the primary key for this table after appending data into the database.


Similarly, we use **append=TRUE** to write these new data to the database.

```{r writebacktodbnew}
RSQLite::dbWriteTable(my_connection,"Category",Category_new,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Customer",Customer_new,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Supplier",Supplier_new,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Warehouse",Warehouse_new,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Product",Product_new,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Shipment",Shipment_new,append=TRUE)
RSQLite::dbWriteTable(my_connection,"Orders",Orders_new,append=TRUE)
```

Use **PRAGMA table_info()** again to verify the primary key, column names, data type, and NOT NULL setting of each table we created.

```{sql connection=my_connection}
PRAGMA table_info(Customer);
```

```{sql connection=my_connection}
PRAGMA table_info(Category);
```

```{sql connection=my_connection}
PRAGMA table_info(Supplier);
```

```{sql connection=my_connection}
PRAGMA table_info(Warehouse);
```

```{sql connection=my_connection}
PRAGMA table_info(Product);
```

```{sql connection=my_connection}
PRAGMA table_info(Shipment);
```

```{sql connection=my_connection}
PRAGMA table_info(Orders);
```


Since the primary of Orders table are a composite of order_id, customer_id, and product_id, so in the 'pk' column it marks these three columns from 1 to 3 and leaves others as 0.


Combine new data to the current tables for the following visualization and analysis.
```{r}
Warehouse <- rbind(Warehouse, Warehouse_new)
Product <- rbind(Product, Product_new)
Customer <- rbind(Customer, Customer_new)
Category <- rbind(Category, Category_new)
Supplier <- rbind(Supplier, Supplier_new)
Orders <- rbind(Orders, Orders_new)
Shipment <- rbind(Shipment, Shipment_new)

```

# Data Pipeline Generation
In this section, we focus on setting up a data pipeline for efficient management and version control of our project using GitHub. The link to the team's GitHub work space is <https://github.com/LETIMEI/Group31_Data-Management>.

## GitHub Repository and Workflow Setup
The objective here is to utilize a GitHub repository to manage our project. We connected our file on Posit Cloud with the GitHub work space, and used 'push' and 'pull' to control the version and synchronize necessary files and script to run in the workflow.

```{r}
GitHub <- readPNG("GitHub_screenshot.png")

grid.raster(GitHub)
```

## GitHub Action for Continuous Integration
By setting up workflows triggered by specific events like pushes or pull requests, we can automate data validation, database updates, and execute basic data analysis tasks seamlessly within our development environment.

We specified the interval for script reruns, identified required packages, defined the script to execute, designated the file path for saved figures, and specified the token name for reference:
```{}
name: Update Repo with result

on:
  schedule:
    - cron: '0 */3 * * *' # Run every 3 hours
  push:
    branches: [ master ]
    
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Setup R environment
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.2.0'
      - name: Cache R packages
        uses: actions/cache@v2
        with:
          path: ${{ env.R_LIBS_USER }}
          key: ${{ runner.os }}-r-${{ hashFiles('**/lockfile') }}
          restore-keys: |
            ${{ runner.os }}-r-
      - name: Install packages
        if: steps.cache.outputs.cache-hit != 'true'
        run: |
          Rscript -e 'install.packages(c("readr","ggplot2","RSQLite", "dplyr","chron","png"))'
      - name: Execute R script
        run: |
          Rscript DataManagement31.R
      - name: Add files
        run: |
          git config --local --unset-all "http.https://github.com/.extraheader"
          git config --global user.email "meimelody1129@gmail.com"
          git config --global user.name "LETIMEI"
          git add --all figures/
      - name: Commit files
        run: |
          git commit -m "Add regression plot figure"
      - name: Pull changes
        run: |
          git pull --no-rebase origin master
      - name: Push changes
        uses: ad-m/github-push-action@v0.6.0
        with:
            github_token: ${{ secrets.MY_TOKEN }}
            branch: master
```


The workflow action would look like the image below, updating whenever we push an updated script or edit the workflow code, or for every 3 hours.
```{r}
Workflow <- readPNG("Workflow_screenshot.png")

grid.raster(Workflow)
```

# Data analysis and visualization

## Calculate Important Values

(1) Rank order value from highest to lowest
```{sql connection=my_connection}
SELECT 
    o.order_id,
    o.customer_id,
    SUM(o.quantity_of_product_ordered * p.product_price - o.voucher_value) AS total_value,
    s.shipping_charge
FROM 
    Orders o
JOIN 
    Product p ON o.product_id = p.product_id
JOIN 
    Shipment s ON o.shipment_id = s.shipment_id
GROUP BY 
    o.order_id, o.customer_id, s.shipping_charge
ORDER BY 
    total_value DESC;
```

(2) Identify Customers with Most Orders:

```{sql connection=my_connection}
SELECT 
    c.customer_id,
    c.first_name, 
    c.last_name, 
    COUNT(*) AS number_of_orders
FROM 
    Orders o
JOIN 
    Customer c ON o.customer_id = c.customer_id
GROUP BY 
    c.customer_id
ORDER BY 
    number_of_orders DESC
LIMIT 5;
```

(3) Identify the Most Profitable Products

```{sql connection=my_connection}

SELECT 
    p.product_name, 
    (o.quantity_of_product_ordered * p.product_price)-
    o.voucher_value  AS total_profit
FROM 
    Orders o
JOIN 
    Product p ON o.product_id = p.product_id
GROUP BY 
    p.product_name
ORDER BY 
    total_profit DESC
LIMIT 5;
```

(4) Calculate Average Order Value by City:

```{sql connection=my_connection}
SELECT 
    c.city, 
    COUNT(*) AS number_of_orders,
    ROUND(AVG(o.quantity_of_product_ordered * (p.product_price - o.voucher_value) + s.shipping_charge),2) AS avg_order_value
FROM 
    Orders o
JOIN 
    Shipment s ON o.shipment_id = s.shipment_id
JOIN 
    Customer c ON o.customer_id = c.customer_id
JOIN 
    Product p ON o.product_id = p.product_id
GROUP BY 
    c.city;
```
(5) Identify Products with the Highest Review Ratings

```{sql connection=my_connection}
SELECT 
    p.product_id,
    p.product_name, 
    ROUND(AVG(o.review_rating),2) AS avg_review_rating
FROM 
    Orders o
JOIN 
    Product p ON o.product_id = p.product_id
GROUP BY 
    p.product_name
ORDER BY 
    avg_review_rating DESC
LIMIT 5;
```


(6) Rank product by their sold quantity
```{sql connection=my_connection}
SELECT 
    p.product_id,
    p.product_name,
    COUNT(*) AS number_of_order,
    SUM(o.quantity_of_product_ordered) AS quantity_sold
FROM 
    Orders o
JOIN 
    Product p ON o.product_id = p.product_id
GROUP BY 
    p.product_id, p.product_name
ORDER BY 
    quantity_sold DESC;
```

(7) Rank categories by sold quantity
```{sql connection=my_connection}
SELECT 
    c.category_id,
    c.category_name,
    COUNT(o.quantity_of_product_ordered) AS total_sold_unit
FROM 
    Orders o
JOIN 
    Product p ON o.product_id = p.product_id
JOIN 
    Category c ON p.category_id = c.category_id
GROUP BY 
    c.category_id, c.category_name
ORDER BY 
    total_sold_unit DESC;
```

(8) Rank parent categories by sold quantity
```{sql connection=my_connection}
SELECT 
    pc.category_id AS parent_category_id,
    pc.category_name AS parent_category_name,
    SUM(o.quantity_of_product_ordered) AS total_sold_unit
FROM 
    Orders o
JOIN 
    Product p ON o.product_id = p.product_id
JOIN 
    Category c ON p.category_id = c.category_id
JOIN 
    Category pc ON c.parent_id = pc.category_id
GROUP BY 
    pc.category_id, pc.category_name
ORDER BY 
    total_sold_unit DESC;
```

(9) Identify the Most Active Customers

```{sql connection=my_connection}
SELECT 
    o.customer_id, 
    c.first_name, 
    c.last_name, 
    COUNT(o.order_id) AS number_of_orders
FROM 
    Orders o
JOIN 
    Customer c ON o.customer_id = c.customer_id
GROUP BY 
    o.customer_id, c.first_name, c.last_name
ORDER BY 
    number_of_orders DESC
LIMIT 5;
```


```{r}
top_categ <- RSQLite::dbGetQuery(my_connection,"SELECT 
    pc.category_id AS parent_category_id,
    pc.category_name AS parent_category_name,
    c.category_id,
    c.category_name,
    COUNT(o.quantity_of_product_ordered) AS total_sold_unit
FROM 
    Orders o
JOIN 
    Product p ON o.product_id = p.product_id
JOIN 
    Category c ON p.category_id = c.category_id
JOIN 
    Category pc ON c.parent_id = pc.category_id
GROUP BY 
    pc.category_id, pc.category_name, c.category_id, c.category_name
ORDER BY 
    pc.category_id, total_sold_unit DESC;
")
```

```{r}
ggplot(top_categ, aes(x = category_name, y = total_sold_unit, fill = parent_category_name)) +
  geom_bar(stat = "identity") +
  labs(x = "Category", y = "Total Sold Units", title = "Total Sold Units by Category") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_discrete(name = "Parent Category")
```


```{r}
top_parent_categ <- RSQLite::dbGetQuery(my_connection,"
                                        SELECT 
    pc.category_id AS parent_category_id,
    pc.category_name AS parent_category_name,
    SUM(o.quantity_of_product_ordered) AS total_sold_unit
FROM 
    Orders o
JOIN 
    Product p ON o.product_id = p.product_id
JOIN 
    Category c ON p.category_id = c.category_id
JOIN 
    Category pc ON c.parent_id = pc.category_id
GROUP BY 
    pc.category_id, pc.category_name
ORDER BY 
    total_sold_unit DESC;
")
```


```{r}
ggplot(top_parent_categ, aes(x = parent_category_name, y = total_sold_unit #, fill = parent_category_name
                             )) +
  geom_bar(stat = "identity") +
  labs(x = "Parent Category", y = "Total Sold Units", title = "Total Sold Units by Parent Category") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_discrete(name = "Parent Category")
```



Rank customer by the number of other customers they referred.
```{sql connection=my_connection}
SELECT 
    c1.customer_id AS customer_id,
    CONCAT(c1.first_name, ' ', c1.last_name) AS customer_name,
    COUNT(c2.referral_by) AS referred_number
FROM 
    Customer c1
LEFT JOIN 
    Customer c2 ON c1.customer_id = c2.referral_by
GROUP BY 
    c1.customer_id, c1.first_name, c1.last_name
ORDER BY 
    referred_number DESC;
```

```{r}
top_recommender <- RSQLite::dbGetQuery(my_connection,"SELECT 
    c1.customer_id AS customer_id,
    CONCAT(c1.first_name, ' ', c1.last_name) AS customer_name,
    COUNT(c2.referral_by) AS referred_number
FROM 
    Customer c1
LEFT JOIN 
    Customer c2 ON c1.customer_id = c2.referral_by
GROUP BY 
    c1.customer_id, c1.first_name, c1.last_name
ORDER BY 
    referred_number DESC
LIMIT 20;
")
```

```{r}
ggplot(top_recommender, aes(x = customer_name, y = referred_number)) +
  geom_bar(stat = "identity", fill = "skyblue") +  # Bar plot with skyblue color
  labs(x = "Customer Name", y = "Number of Referrals", title = "Top 20 Recommenders") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip() 
```



Warehouse capacity v.s. current stock level

```{r barplot}
barplot(Warehouse$capacity, col = "steelblue", ylim = c(0, max(Warehouse$capacity, Warehouse$current_stock)),
        main = "Warehouse Capacity and Current Stock", xlab = "Warehouse ID", ylab = "Quantity")
barplot(Warehouse$current_stock, col = "lightpink", add = TRUE)
legend("topright", legend = c("Capacity", "Current Stock"), fill = c("steelblue", "lightpink"))
```

Product price distribution

```{r}
# Calculate the mean price
mean_price <- mean(Product$product_price)

# Create the histogram
ggplot(Product, aes(x = product_price)) +
  geom_histogram(binwidth = 1, position = "identity") +
  geom_vline(xintercept = mean_price, linetype = "dotted", color = "darkred") +  # Add the mean line
  labs(x = "Product Price", y = "Frequency", fill = "Category ID",
       title = "Distribution of Product Prices by Category") +
  theme_minimal()

```

Number of customers in each city

```{r}
city_counts <- Customer %>%
  group_by(city) %>%
  summarise(num_customers = n())

# Plot the counts
ggplot(city_counts, aes(x = reorder(city, -num_customers), y = num_customers)) +
  geom_bar(stat = "identity") +
  labs(x = "City", y = "Number of Customers",
       title = "Number of Customers in Each City") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Product review rating ranking from highest to lowest

```{r}
# Calculate the average rating for each product
class(Orders$review_rating)
Orders$review_rating <- as.numeric(Orders$review_rating)
product_ratings <- Orders %>%
  group_by(product_id) %>%
  summarise(avg_rating = mean(review_rating, na.rm = TRUE))

# Sort products by average rating in descending order
product_ratings <- product_ratings[order(-product_ratings$avg_rating),]

top_products <- product_ratings[product_ratings$avg_rating == 5,]


ggplot(product_ratings, aes(x = reorder(product_id, -avg_rating), y = avg_rating, fill = factor(product_id %in% top_products$product_id))) +
  geom_bar(stat = "identity") +
  labs(x = "Product ID", y = "Average Rating",
       title = "Average Rating for Each Product") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 0)) +
  scale_fill_manual(values = c("grey80", "darkred"), guide = FALSE)

```

```{r}
Orders$order_date <- as.Date(Orders$order_date)
Orders$quantity_of_product_ordered <- as.numeric(Orders$quantity_of_product_ordered)

agg_data <- Orders %>%
  group_by(order_date) %>%
  summarise(total_quantity = sum(quantity_of_product_ordered))

# Plot using ggplot
ggplot(agg_data, aes(x = order_date, y = total_quantity)) +
  geom_line(stat = "identity", color = "steelblue") +
  labs(x = "Order Date", y = "Total Quantity Ordered", title = "Number of Products Ordered per Day")
```


```{r}
sales_data <- Orders %>%
  inner_join(Product, by = "product_id") %>%
  inner_join(Category, by = "category_id") %>%
  group_by(order_date, parent_id, parent_name) %>%
  summarise(units_sold = sum(quantity_of_product_ordered))

ggplot(sales_data, aes(x = order_date, y = units_sold, color = parent_name)) +
  geom_line() +
  labs(x = "Order Date", y = "Units Sold", title = "Units Sold by Parent Category Across Time") +
  scale_color_discrete(name = "Parent Category")
```


=======
>>>>>>> 61b49273c2c69a33c1fc130db359f453a1872bcf